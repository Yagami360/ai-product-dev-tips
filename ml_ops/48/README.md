# FastAPI を使用した非同期処理での Web-API の構築（FastAPI + uvicorn + gunicorn + バッチサーバー + docker での構成で動画データを扱うケース）

「[FastAPI を使用した非同期処理での Web-API の構築（FastAPI + uvicorn + gunicorn + redis + バッチサーバー + docker での構成で画像データを扱うケース）](https://github.com/Yagami360/MachineLearning_Tips/tree/master/server_processing/36)」記載の方法では、Redis のキューデータに画像データを保存し、非同期 API を実現していたが、Redis のキューデータ上に大容量の動画データを保存するとメモリを多量に消費してしまい OutOfMemory エラーが発生する懸念があるので、ここでは、ローカルディスクに job_id のフォルダを作成し、そのディレクトリをキューデータとして使用し、非同期 API を実現する

- プロキシサーバー（uvicorn + gunicorn + FastAPI）
    - 非同期処理を行うジョブを定義
- バッチサーバー（＝ジョブの投入から終了までを管理するサーバー）
    - redis のジョブキューを定期的にポーリングして、キューにデータが存在すれば推論サーバーにリクエストする。推論サーバーからのレスポンスデータを redis にレスポンスデータを保存する
- 推論サーバー
    - API の本来の処理を行うサーバー。
    ここでは、簡単のため推論サーバーとして ffppeg を使用した動画の無音化を行う処理にしているが、機械学習 API の場合は、この推論サーバーの部分が動画の機械学習モデルの推論処理になる

## ■ API 構成図

## ■ 使用法

1. プロキシサーバーのコードを作成する<br>
    FastAPI を用いて、例えば以下のようなプロキシサーバーのコードを作成する。<br>    
    ```python
    ```

    > 動画データをリクエストする場合は、

    > `job_id` に対応した

1. バッチサーバーのコードを作成する<br>
    バッチサーバーでは、Redis のデータを定期的にポーリングし、データがあれば推論サーバーにリクエスト処理する。
    その後、推論サーバーからのレスポンスデータをローカルディスクのキューデータディレクトリに保存する。

    バッチサーバーでのポーリング処理は、`asyncio` と `concurrent.futures.ProcessPoolExecutor` を使用した並列処理で行う。

    ```python
    ```

1. 推論サーバーのコードを作成する<br>
    ここでは例えば、ffppeg を使用した動画の無音化処理を行う推論サーバーを構築する。
    機械学習 API の場合は、この推論サーバーの部分が機械学習モデルを使用した推論処理になる。

    ```python
    ```

1. docker-compose で API を構成する<br>
    プロキシサーバー・バッチサーバー・推論サーバーを docker-compose で構築する。
    ```python
    ```

1. リクエスト処理のコードを作成する<br>
    `requests` モジュールを用いて、例えば以下のようなリクエスト処理のコードを作成する。
    
    ```python
    ```

1. API を起動する<br>
    ```sh
    $ docker-compose -f docker-compose.yml stop
    $ docker-compose -f docker-compose.yml up -d
    ```

1. リクエスト処理する<br>
    上記作成したリクエスト処理のコードを用いてリクエスト処理する場合は、以下のコマンドを実行する
    ```sh
    ```
