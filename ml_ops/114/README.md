# SLURM を使用して複数サーバーでの分散学習を行う

<img width="800" alt="image" src="https://github.com/user-attachments/assets/6045435e-6c1f-4fd3-ba0d-8ef7ec8fce3a" />

## 方法（Ubuntu や Debian の場合）

1. 複数サーバーを用意する<br>
    マスターノードのサーバー A とワーカーノードのサーバー B を用意する

1. サーバーのホスト名を設定する<br>
    `slurm.conf` で定義するホスト名 `SlurmctldHost`, `NodeName` の名前解決を行うため、両方のサーバーの `/etc/hosts` をそれぞれ編集する
    ```bash
    sudo vi /etc/hosts
    ```

    `/etc/hosts` に以下の行を追加する
    ```
    <サーバー A のIPアドレス（内部IP）>    server-a（サーバーAのホスト名）
    <サーバー B のIPアドレス（内部IP）>    server-b（サーバーBのホスト名）
    ```

1. 両方のサーバーのポートを開放する<br>
    ファイアウォールで `slurm.conf` で定義したポート `SlurmctldPort` を開放し、相互に通信できるようにする

    - GCE の場合<br>
        1. VPCネットワーク → ファイアウォール → ファイアウォールルールを作成
            - 名前: `allow-slurm-cluster`
            - ターゲットタグ: `slurm-cluster`（または適切なタグ）
            - ソースIPの範囲: `xx.xxx.0.0/16`（サーバー A と サーバー B の内部IPの範囲になるように指定）
            - プロトコルとポート:
                - `tcp:6817-6818`（`slurm.conf` の `SlurmctldPort` と `SlurmdPort` で定義したポート番号になるように指定）
                - `tcp:35000-45000`（`slurm.conf` の `SrunPortRange` で定義したポート範囲になるように指定）
                - その他: `icmp`（ping で疎通確認できるようにする）

        1. 両方の GCE インスタンス（サーバーA & サーバーB）のネットワークタグに `slurm-cluster` を追加する

1. （オプション）ping で疎通確認を行う<br>
    ```bash
    ping server-a
    ping server-b
    ```

1. 複数サーバーに SLURM をインストールする<br>
    [SLURM をインストールする](https://github.com/Yagami360/ai-product-dev-tips/tree/master/ml_ops/112)　に従って、サーバー A には、`slurmctld` と `slurmd` をインストールし、サーバー B には、`slurmd` をインストールする

1. （オプション）複数サーバーの slurm 用ユーザー `slurm` の ID を一致させる<br>
    サーバー A と サーバー B の `slurm` 用ユーザーの ID が異なる場合は、同じ ID になるように変更する
    `slurm.conf` で定義した `SlurmUser` の ID を一致させる
    ```bash
    # USER ID を確認する
    id slurm
    ```

    例えば、USER ID が 5000 の場合は、以下のように設定する
    ```bash
    sudo usermod -u 5000 slurm
    sudo groupmod -g 5000 slurm
    ```

1. 複数サーバー間を ssh で接続できるようにする<br>
    サーバー A と サーバー B の間で ssh で接続できるようにする。

    1. サーバーBで SSH 秘密鍵と公開鍵を作成する<br>
        ```bash
        cd .ssh
        ssh-keygen
        ```

    2. 作成された公開鍵 `id_rsa.pub` をサーバーAの　`.ssh/authorized_keys` に追加する

1. 複数サーバーの `slurm.conf` を設定する<br>
    両方のサーバーの `slurm.conf` を設定する

    - サーバー A と サーバー B の `slurm.conf`（同じ内容にする必要あり）<br>
        ```conf
        # slurm.conf file generated by configurator easy.html.
        # Put this file on all nodes of your cluster.
        # See the slurm.conf man page for more information.
        #
        ClusterName=dgx-cluster
        SlurmctldHost=server-a      # マスターノード（サーバーA）のホスト名
        #
        #MailProg=/bin/mail
        MpiDefault=none
        #MpiParams=ports=12000-12999
        # ProctrackType=proctrack/cgroup
        # ProctrackType=proctrack/linuxproc
        # ReturnToService=1
        SlurmctldPidFile=/var/run/slurmctld.pid
        SlurmdPidFile=/var/run/slurmd.pid
        SlurmdSpoolDir=/var/spool/slurmd
        SlurmUser=slurm
        #SlurmdUser=root
        StateSaveLocation=/var/spool/slurmctld
        SwitchType=switch/none
        TaskPlugin=task/affinity,task/cgroup
        #
        #
        # TIMERS
        #KillWait=30
        #MinJobAge=300
        #SlurmctldTimeout=120
        #SlurmdTimeout=300
        #
        #
        # SCHEDULING
        SchedulerType=sched/backfill
        SelectType=select/cons_tres
        #
        #
        # LOGGING AND ACCOUNTING
        AccountingStorageType=accounting_storage/none
        #JobAcctGatherFrequency=30
        JobAcctGatherType=jobacct_gather/none
        #SlurmctldDebug=info
        SlurmctldLogFile=/var/log/slurmctld.log
        #SlurmdDebug=info
        SlurmdLogFile=/var/log/slurmd.log
        #
        #
        # COMPUTE NODES（'/usr/local/sbin/slurmd -C' で確認可能）
        NodeName=server-a CPUs=4 Boards=1 SocketsPerBoard=1 CoresPerSocket=2 ThreadsPerCore=2 RealMemory=15033
        NodeName=server-b CPUs=4 Boards=1 SocketsPerBoard=1 CoresPerSocket=2 ThreadsPerCore=2 RealMemory=15033
        # NodeName=server-b CPUs=4 Boards=1 SocketsPerBoard=1 CoresPerSocket=2 ThreadsPerCore=2 RealMemory=15033 Gres=gpu:1
        PartitionName=debug Nodes=ALL Default=YES MaxTime=INFINITE State=UP

        # GPU設定
        # GresTypes=gpu

        # ポート設定
        SlurmctldPort=6817          # slurmctld で使用するポート番号
        SlurmdPort=6818             # slurmd で使用するポート番号
        SrunPortRange=35000-45000   # srun コマンドで使用するポート範囲
        CommunicationParameters=NoAddrCache
        TCPTimeout=5

        # タイムアウト設定
        MessageTimeout=60
        ReturnToService=2
        SlurmdTimeout=300
        SlurmctldTimeout=300
        ```

1. 複数サーバーの MUNGE キーを一致させる<br>
    ```bash
    sudo cat /etc/munge/munge.key
    ```

    サーバー A と サーバー B の `munge.key` の内容が一致していることを確認する。
    一致していない場合は、サーバー A の `munge.key` をサーバー B にコピーする
    ```bash
    # サーバー A で実行
    sudo scp /etc/munge/munge.key username@server-b:/tmp/munge.key

    # サーバー B で実行
    sudo mv /tmp/munge.key /etc/munge/munge.key
    sudo chown munge:munge /etc/munge/munge.key
    sudo chmod 400 /etc/munge/munge.key
    ```

    その後、両方のサーバーで MUNGE を再起動する
    ```bash
    sudo systemctl restart munge
    ```

1. 複数サーバーの `slurmctld` と `slurmd` を起動する<br>

    - サーバー A : `slurmctld` と `slurmd` を起動する
        ```bash
        sudo systemctl daemon-reload
        sudo systemctl start slurmctld slurmd
        ```

    - サーバー B : `slurmd` のみを起動する
        ```bash
        sudo systemctl daemon-reload
        sudo systemctl start slurmd
        ```

1. ノードの状態を確認する<br>
    ```bash
    sinfo
    ```
    ```
    PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
    debug*       up   infinite      2   idle server-a,server-b
    ```

    ```bash
    scontrol show node
    ```

1. 学習用ジョブのスクリプトを作成する<br>

1. マスターノード（サーバーA）からワーカーノード（サーバーB）にジョブを投入する<br>

    - srun コマンドを使用する場合<br>
        ```bash
        srun --nodelist=server-b --ntasks=1 --ntasks-per-node=1 python train.py
        ```

        GPU の分散学習を行う場合は、`--gres=gpu:0` オプションを追加する
        ```bash
        srun --nodelist=server-b --ntasks=1 --ntasks-per-node=1 --gres=gpu:0 python train.py
        ```

    - sbatch コマンドを使用する場合<br>
        ```bash
        sbatch train.sh
        ```

        GPU の分散学習を行う場合は、`--gres=gpu:0` オプションを追加する
        ```bash
        sbatch --gres=gpu:0 train.sh
        ```

1. （オプション）Docker で動作する学習ジョブの場合<br>
    計算ノード（server-b）上の Docker で動作する学習ジョブを動かしそうとして、以下のエラーが出た場合
    ```sh
    srun --nodelist=server-b --ntasks=1 --ntasks-per-node=1 train_docker.sh
    ```
    ```sh
    Building Docker image slurm-exercises-train-job:latest...
    permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Head "http://%2Fvar%2Frun%2Fdocker.sock/_ping": dial unix /var/run/docker.sock: connect: permission denied
    srun: error: server-b: task 0: Exited with exit code 1
    ERROR: mkdir /home/sakai/.docker/buildx: permission denied
    ```

    以下のように、計算ノード（server-b）側で `docker` グループに `slurm` ユーザーを追加し、`docker` サービスを再起動する
    ```bash
    sudo usermod -aG docker slurm
    ```
    ```bash
    sudo systemctl restart docker
    sudo systemctl restart slurmd
    ```

    依然としてエラーが発生する場合は、以下のコマンドも実行する
    ```bash
    # Dockerソケットのパーミッションを確認と修正
    ls -l /var/run/docker.sock
    sudo chmod 666 /var/run/docker.sock
    ```
    ```bash
    # .dockerディレクトリの所有権を修正
    sudo mkdir -p /home/sakai/.docker
    sudo chown -R sakai:sakai /home/sakai/.docker
    sudo mkdir -p /var/lib/slurm/.docker
    sudo chown -R slurm:slurm /var/lib/slurm/.docker
    ```

1. ジョブの状態を確認する<br>
    ```bash
    squeue --format="%.18i %.9P %.30j %.8u %.8T %.9M %.4D %R"
    ```
    ```
    JOBID PARTITION                           NAME     USER    STATE      TIME NODE NODELIST(REASON)
    53     debug                python train.py    sakai  RUNNING      3:52    1 server-b
    ```
